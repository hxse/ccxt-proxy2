import pandas as pd
from pathlib import Path

from .cache_utils import get_sorted_cache_files, get_file_info
from .cache_file_io import write_to_cache, read_cache_file
from .cache_data_processor import merge_with_deduplication


def handle_overlap_at_end(
    sorted_cache_files: list[Path],
    new_data: pd.DataFrame,
    cache_size: int,
    file_type: str,
) -> tuple[pd.DataFrame, list[Path]]:
    """
    å¤„ç†æ–°æ•°æ®ç»“æŸæ—¶é—´ç‚¹ä¸æ—§æ•°æ®å¼€å§‹æ—¶é—´ç‚¹é‡å çš„æƒ…å†µã€‚
    å¦‚æœæ—§æ–‡ä»¶å¤§å°å°äº cache_sizeï¼Œåˆ™åˆå¹¶æ—§æ•°æ®åˆ°æ–°æ•°æ®ï¼Œå¹¶æ ‡è®°æ—§æ–‡ä»¶å¾…åˆ é™¤ã€‚
    """
    files_to_delete = []
    new_data_end = new_data.iloc[-1, 0]

    for f in sorted_cache_files:
        info = get_file_info(f.name)
        if not info:
            continue
        old_data_start = info["start_time"]

        # æ–°æ•°æ®ç»“æŸæ—¶é—´ç‚¹ == æ—§æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ ä¸” æ—§æ•°æ®å¤§å°å°äº cache_size -> åˆå¹¶æ—§æ•°æ®åˆ°æ–°æ•°æ®ï¼Œåˆ é™¤æ—§æ–‡ä»¶
        if new_data_end == old_data_start:
            # æ£€æŸ¥æ—§æ•°æ®å¤§å°ï¼Œåªæœ‰å°äº cache_size æ‰è€ƒè™‘åˆå¹¶
            old_file_info = get_file_info(f.name)
            if old_file_info and old_file_info["count"] < cache_size:
                print(
                    f"ğŸ”„ æ–°æ•°æ®ç»“æŸæ—¶é—´ç‚¹ == æ—§æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ï¼Œä¸”æ—§æ–‡ä»¶å°äº {cache_size}ï¼Œè¿›è¡Œåˆå¹¶ã€‚"
                )
                old_data = read_cache_file(f, file_type)
                new_data = merge_with_deduplication(new_data, old_data)
                files_to_delete.append(f)
                # æ›´æ–°æ–°æ•°æ®çš„ç»“æŸæ—¶é—´ä¸ºåˆå¹¶åçš„ç»“æŸæ—¶é—´
                new_data_end = new_data.iloc[-1, 0]
    return new_data, files_to_delete


def handle_overlap_at_start(
    sorted_cache_files: list[Path],
    new_data: pd.DataFrame,
    cache_size: int,
    file_type: str,
) -> tuple[pd.DataFrame, list[Path]]:
    """
    å¤„ç†æ–°æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ä¸æ—§æ•°æ®ç»“æŸæ—¶é—´ç‚¹é‡å çš„æƒ…å†µã€‚
    å¦‚æœæ—§æ–‡ä»¶å¤§å°å°äº cache_sizeï¼Œåˆ™åˆå¹¶æ—§æ•°æ®åˆ°æ–°æ•°æ®ï¼Œå¹¶æ ‡è®°æ—§æ–‡ä»¶å¾…åˆ é™¤ã€‚
    """
    files_to_delete = []
    new_data_start = new_data.iloc[0, 0]

    for f in sorted_cache_files[::-1]:
        info = get_file_info(f.name)
        if not info:
            continue
        old_data_end = info["end_time"]

        # æ–°æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ == æ—§æ•°æ®ç»“æŸæ—¶é—´ç‚¹ ä¸” æ—§æ•°æ®å¤§å°å°äº cache_size -> åˆå¹¶æ—§æ•°æ®åˆ°æ–°æ•°æ®ï¼Œåˆ é™¤æ—§æ–‡ä»¶
        if new_data_start == old_data_end:
            # æ£€æŸ¥æ—§æ•°æ®å¤§å°ï¼Œåªæœ‰å°äº cache_size æ‰è€ƒè™‘åˆå¹¶
            old_file_info = get_file_info(f.name)
            if old_file_info and old_file_info["count"] < cache_size:
                print(
                    f"ğŸ”„ æ–°æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ == æ—§æ•°æ®ç»“æŸæ—¶é—´ç‚¹ï¼Œä¸”æ—§æ–‡ä»¶å°äº {cache_size}ï¼Œè¿›è¡Œåˆå¹¶ã€‚"
                )
                old_data = read_cache_file(f, file_type)
                new_data = merge_with_deduplication(old_data, new_data)  # æ³¨æ„åˆå¹¶æ–¹å‘
                files_to_delete.append(f)
                # æ›´æ–°æ–°æ•°æ®çš„å¼€å§‹æ—¶é—´ä¸ºåˆå¹¶åçš„å¼€å§‹æ—¶é—´
                new_data_start = new_data.iloc[0, 0]
    return new_data, files_to_delete


def adjust_write_range_and_delete_overlapped(
    sorted_cache_files: list[Path],
    new_data: pd.DataFrame,
    new_data_start: int,
    new_data_end: int,
) -> tuple[int, int, list[Path]]:
    """
    è°ƒæ•´æ–°æ•°æ®å†™å…¥èŒƒå›´å¹¶æ ‡è®°å®Œå…¨è¦†ç›–çš„æ—§æ–‡ä»¶ä¸ºå¾…åˆ é™¤ã€‚
    """
    start_time_to_write = new_data_start
    end_time_to_write = new_data_end
    files_to_delete = []

    for f in sorted_cache_files:
        info = get_file_info(f.name)
        if not info:
            continue
        old_data_start = info["start_time"]
        old_data_end = info["end_time"]

        # 1. æ–°æ•°æ®å®Œå…¨åœ¨æ—§æ•°æ®å†…éƒ¨ï¼ˆå®Œå…¨è¢«ç¼“å­˜ï¼‰ -> æ— éœ€å†™å…¥ï¼Œç›´æ¥è¿”å›
        if new_data_start >= old_data_start and new_data_end <= old_data_end:
            print(
                f"âœ… æ–°æ•°æ® ({new_data_start}-{new_data_end}) å·²è¢«ç¼“å­˜æ–‡ä»¶ ({old_data_start}-{old_data_end}) å®Œå…¨è¦†ç›–ï¼Œæ— éœ€å†™å…¥ã€‚"
            )
            return -1, -1, []  # è¿”å›ç‰¹æ®Šå€¼è¡¨ç¤ºæ— éœ€å†™å…¥

        # 2. æ–°æ•°æ®å®Œå…¨è¦†ç›–æ—§æ•°æ® -> æ ‡è®°æ—§æ–‡ä»¶ä¸ºåˆ é™¤
        elif new_data_start <= old_data_start and new_data_end >= old_data_end:
            print(
                f"ğŸ”„ æ–°æ•°æ® ({new_data_start}-{new_data_end}) å®Œå…¨è¦†ç›–æ—§ç¼“å­˜æ–‡ä»¶ ({old_data_start}-{old_data_end})ï¼Œæ ‡è®°ä¸ºåˆ é™¤ã€‚"
            )
            files_to_delete.append(f)

        # 3. æ–°æ•°æ®åœ¨æ—§æ•°æ®ä¹‹å‰ä¸”æœ‰é‡å  -> è°ƒæ•´å†™å…¥çš„ç»“æŸæ—¶é—´ï¼Œä½¿å…¶ä¸åŒ…å«é‡å éƒ¨åˆ†
        elif new_data_end > old_data_start and new_data_start < old_data_start:
            end_time_to_write = min(end_time_to_write, old_data_start)
            print(
                f"âš ï¸ æ–°æ•°æ® ({new_data_start}-{new_data_end}) ä¸æ—§ç¼“å­˜ ({old_data_start}-{old_data_end}) é‡å ï¼Œè°ƒæ•´å†™å…¥ç»“æŸæ—¶é—´ã€‚"
            )

        # 4. æ–°æ•°æ®åœ¨æ—§æ•°æ®ä¹‹åä¸”æœ‰é‡å  -> è°ƒæ•´å†™å…¥çš„èµ·å§‹æ—¶é—´ï¼Œä½¿å…¶ä¸åŒ…å«é‡å éƒ¨åˆ†
        elif new_data_start < old_data_end and new_data_end > old_data_end:
            start_time_to_write = max(start_time_to_write, old_data_end)
            print(
                f"âš ï¸ æ–°æ•°æ® ({new_data_start}-{new_data_end}) ä¸æ—§ç¼“å­˜ ({old_data_start}-{old_data_end}) é‡å ï¼Œè°ƒæ•´å†™å…¥èµ·å§‹æ—¶é—´ã€‚"
            )
    return start_time_to_write, end_time_to_write, files_to_delete


def handle_cache_write(
    symbol: str,
    period: str,
    new_data: pd.DataFrame,
    cache_dir: Path,
    cache_size: int,
    file_type: str = "parquet",
) -> None:
    """
    å¤„ç†æ–°æ•°æ®å†™å…¥ç¼“å­˜çš„é€»è¾‘ï¼ŒåŒ…æ‹¬å¤„ç†é‡å å’Œè¦†ç›–æƒ…å†µã€‚

    æ­¤å‡½æ•°é‡‡ç”¨â€œå…ˆå¤„ç†åå†™å…¥â€çš„ç­–ç•¥ï¼Œé€šè¿‡è®°å½•é‡å è¾¹ç•Œï¼Œæœ€åä¸€æ¬¡æ€§å¯¹æ–°æ•°æ®è¿›è¡Œåˆ‡ç‰‡å¹¶å†™å…¥ã€‚
    """
    if new_data.empty:
        return

    # å¤„ç†æ–°æ•°æ®ç»“æŸæ—¶é—´ç‚¹ä¸æ—§æ•°æ®å¼€å§‹æ—¶é—´ç‚¹é‡å çš„æƒ…å†µ
    sorted_cache_files = get_sorted_cache_files(cache_dir, symbol, period, file_type)
    new_data, files_to_delete_end = handle_overlap_at_end(
        sorted_cache_files, new_data, cache_size, file_type
    )
    for f in files_to_delete_end:
        if f.exists():
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§ç¼“å­˜æ–‡ä»¶: {f.name}")
            f.unlink()

    # å¤„ç†æ–°æ•°æ®å¼€å§‹æ—¶é—´ç‚¹ä¸æ—§æ•°æ®ç»“æŸæ—¶é—´ç‚¹é‡å çš„æƒ…å†µ
    sorted_cache_files = get_sorted_cache_files(cache_dir, symbol, period, file_type)
    new_data, files_to_delete_start = handle_overlap_at_start(
        sorted_cache_files, new_data, cache_size, file_type
    )
    for f in files_to_delete_start:
        if f.exists():
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§ç¼“å­˜æ–‡ä»¶: {f.name}")
            f.unlink()

    # è°ƒæ•´å†™å…¥èŒƒå›´å¹¶æ ‡è®°å®Œå…¨è¦†ç›–çš„æ—§æ–‡ä»¶ä¸ºå¾…åˆ é™¤
    sorted_cache_files = get_sorted_cache_files(cache_dir, symbol, period, file_type)
    new_data_start = new_data.iloc[0, 0]
    new_data_end = new_data.iloc[-1, 0]
    start_time_to_write, end_time_to_write, files_to_delete_overlap = (
        adjust_write_range_and_delete_overlapped(
            sorted_cache_files, new_data, new_data_start, new_data_end
        )
    )
    for f in files_to_delete_overlap:
        if f.exists():
            print(f"ğŸ—‘ï¸ åˆ é™¤æ—§ç¼“å­˜æ–‡ä»¶: {f.name}")
            f.unlink()

    if start_time_to_write == -1 and end_time_to_write == -1:
        # è¡¨ç¤ºæ–°æ•°æ®å·²å®Œå…¨è¢«ç¼“å­˜æ–‡ä»¶è¦†ç›–ï¼Œæ— éœ€å†™å…¥
        return

    # æœ€åæ ¹æ®è°ƒæ•´åçš„æ—¶é—´èŒƒå›´è¿›è¡Œåˆ‡ç‰‡å’Œå†™å…¥
    data_to_write = new_data[
        (new_data["time"] >= start_time_to_write)
        & (new_data["time"] <= end_time_to_write)
    ]

    if not data_to_write.empty:
        write_to_cache(symbol, period, data_to_write, cache_dir, cache_size, file_type)
    else:
        print("âŒ ç»è¿‡å¤„ç†ï¼Œæ²¡æœ‰æ•°æ®éœ€è¦å†™å…¥ç¼“å­˜ã€‚")
