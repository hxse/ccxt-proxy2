# 放弃的方案对比

> **注意**：本文档描述的所有方案都是**已放弃的方案**。本文的目的是解释为什么这些方案不适合本项目，帮助理解当前设计的选择。这些方案与本项目的最终实现无关。

---

## 方案概览

| 方案 | 核心思想 | 为什么放弃 |
|------|---------|-----------|
| 按大小分块 + 首尾重叠 | 固定数据行数分块 | 合并/碎片整理逻辑过于复杂 |
| 单文件方案 | 无分块 | 无法验证数据连续性 |
| batch_id 内嵌方案 | 数据中嵌入 batch 信息 | batch 合并逻辑复杂度回升 |

---

## 放弃的方案一：按大小分块 + 首尾重叠

### 文件结构
```
BTC_USDT 15m 20230101T060000Z 20230101T093000Z 0015.parquet
BTC_USDT 15m 20230101T093000Z 20230101T120000Z 0015.parquet
```

### 核心逻辑
- 每个文件存储固定数量（`cache_size`）的数据行
- 后一个文件的首条数据 = 前一个文件的尾条数据（首尾重叠）
- 通过文件名比较判断连续性

### 为什么放弃

| 问题 | 需要的逻辑 |
|------|-----------|
| 分块边界计算 | `get_chunk_slices`，处理正向/反向 |
| 追加数据 | `handle_cache_write` 处理多种重叠情况 |
| 碎片整理 | `consolidator` 合并小文件，需要判断"满文件序列" |
| 读取数据 | 找起始文件→加载多个→合并→去重 |

**代码行数**：~800 行

**结论**：复杂度过高，容易出错，难以维护。

---

## 放弃的方案二：单文件方案

### 文件结构
```
BTC_USDT_15m.parquet   ← 所有数据一个文件
```

### 为什么放弃

| 优点 | 缺点 |
|------|------|
| 最简单 | 无法验证连续性 |
| 无需管理多文件 | 丢失获取历史信息 |
| | 无法区分"数据缺失"和"节假日缺失" |

**结论**：无法满足"区分数据缺失 vs 节假日缺失"的核心需求。

---

## 放弃的方案三：batch_id 内嵌方案

### 文件结构
```python
# 数据中包含 __batch_id__ 列
df = [time, open, high, low, close, volume, __batch_id__]
```

### 核心逻辑
- 每次获取的数据带上 batch_id
- 通过 batch_id 判断数据来源
- 首尾重叠的数据保留相同 time 但不同 batch_id

### 为什么放弃

| 问题 | 说明 |
|------|------|
| batch_id 需要动态合并 | 如果首尾连接或包含，需要把 batch_id 改成一样的 |
| 读取时需要去重处理 | 相同 time 可能有多条记录 |
| 日志信息受限 | 只有 batch_id，无法记录获取时间、来源等元数据 |

**结论**：batch_id 合并逻辑的复杂度与"按大小分块"方案相当，没有真正简化问题。

---

## 复杂度对比

```
                    写入    读取    追加    合并    验证    总复杂度
按大小分块           ████    ████    █████   █████   ██      ████████████████████
单文件               █       █       █       -       -       ███
batch_id 内嵌        ██      ███     ██      ████    ██      █████████████
按时间分块+日志分离  ██      █       ██      █       ██      ████████ (当前方案)
```

---

## 为什么按时间分块比按大小分块简单

| 维度 | 按大小分块 | 按时间分块 |
|------|-----------|-----------|
| **分块边界** | 动态计算，依赖数据量 | 固定（月初/年初/10年初） |
| **边界重叠** | 需要首尾重叠保证连续性 | 不需要，时间边界天然对齐 |
| **追加数据** | 可能跨多个块，需要分割 | 最多跨 2 个块（跨月/跨年） |
| **碎片整理** | 需要 consolidator | 不需要 |
| **文件命名** | 需要编码 start/end/count | 只需要年份或月份 |
| **判断归属** | 需要遍历查找 | 直接从时间戳提取 |

---

## 总结

这些方案被放弃的共同原因：

1. **复杂度过高**：需要处理各种边界情况和合并逻辑
2. **难以维护**：代码量大，测试用例多，容易出错
3. **无法满足需求**：单文件方案无法验证连续性

当前选择的"按时间分块 + 日志分离"方案是经过对比后的最佳平衡点。
